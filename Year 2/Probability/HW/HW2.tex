\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{tikz}
\usepackage{stmaryrd}

\usepackage[left=1cm,right=1cm,top=2cm,bottom=2cm]{geometry}
\author{Marco Biroli}
\title{HW2 - Probability}

\begin{document}
\maketitle

\section{Change of variables}
\begin{enumerate}

\item From the change of variable theorem we know that:
\[
f_{U, V}(u, v) = f_{X, Y}(uv, v(1 - u)) |J|^{-1}
\]
Where:
\[
J = \begin{vmatrix}
\frac{y}{(x+y)^2} & -\frac{x}{(x+y)^2}\\
1 & 1
\end{vmatrix} = \frac{1}{x+y} =  v^{-1}
\]
Then replacing in the definition and using the fact that $X$ and $Y$ are independent and hence we can split the joint law we get that:
\begin{align*}
f_{U,V}(u, v) &= \frac{uv^{k-1}}{(k-1)!} e^{-uv} 1_{\mathbb{R}^+}(uv) \frac{v^{k-1}(1 - u)^{k-1}}{(k - 1)!} e^{-v(1- u)} 1_{\mathbb{R}^+} (v(1 - u)) v\\
&= \frac{e^{-v} \sqrt{v^2} \left((1-u) u
   v^2\right)^{k-1}}{((k-1)!)^2} 1_{\mathbb{R}^+} (u v) 1_{\mathbb{R}^+}(v-u v)
\end{align*}
Then integrating for $u$ on $\mathbb{R}$ gives:
\[
f(v) = ...
\]

\item ...

\end{enumerate}

\section{Order statistics}

\begin{enumerate}

\item Let $(\Omega_i, \mathcal{F}_i, P_i)$ be the probability space of $X_i$ then define the product probability space as $(\Omega, \mathcal{F}, P)$. Let $(\llbracket 1, n \rrbracket, \mathcal{P}(\llbracket 1, n \rrbracket), P')$ be the probability space of $T$. Then define the probability space $(\Omega', \mathcal{F}', P')$ as the product probability space of the two previous ones. Then we define:
\begin{align*}
X_T : \Omega \times \llbracket 1, n \rrbracket &\longrightarrow \mathbb{R}\\
(\vb{x}, i) &\longmapsto x_i
\end{align*}
Then let $B \in \mathcal{B}(\mathbb{R})$ then we have that:
\begin{align*}
\{(\omega, i) \in \Omega' : X_T(\omega, i) \in B\} &\subset \bigotimes_{i \in \llbracket 1, n \rrbracket} \{\omega_i \in \Omega_i : \exists i,  X_i(\omega) \in B\} \times \llbracket 1, n \rrbracket \in \mathcal{F}'
\end{align*}
Where the belonging to $\mathcal{F}'$ follows from the definition of the product $\sigma$-algebra. 

\item I think that $(X_{(1)}, \cdots, X_{(n)})$ is ill-defined since there exists no clear order relation on functions which might not even come from the same space. I assume that what was meant was that:
\[
\forall \omega \in \Omega, \exists \sigma \in \mathfrak{S}_n, \sigma(X(\omega)) = \sigma\left(\left(X_1(\omega_1), \cdots, X_n(\omega_n)\right)\right) = (X_{\sigma(1)}(\omega_{\sigma(1)}), \cdots, X_{\sigma(n)}(\omega_{\sigma(n)})) \mbox{~~ is in increasing order.} 
\]
Then admitting the axiom of choice let $\omega \in \Omega$ then since we have a finite list of real numbers we know from the constructions of the real numbers we can order it. Then we define the permutation $\sigma_\omega$ as the one which sets them in the right order and in case of parity the smaller index goes first. Then we have that $\sigma$ is a random variable defined as:
\begin{align*}
\sigma : \Omega &\longrightarrow \mathfrak{S}_n\\
\omega &\longmapsto \sigma_\omega
\end{align*}
We furthermore have that $\sigma$ is injective and therefore measurable. Hence $\sigma$ is a well-defined random variable.

\item From the previous question we have that:
\begin{align*}
\mathbb{E}[\varphi(X_{(1)}, \cdots, X_{(n)} - X_{(n-1)})] &= \mathbb{E}[\varphi(X_{\sigma(1)}, \cdots, X_{\sigma(n)} - X_{\sigma(n-1)})]\\
&= \int_{\omega \in \Omega} \varphi(\sigma(X(\omega))) P'(\sigma(X(\omega)))  \dd \omega \\
&= \int_{\omega \in \Omega} \varphi(\sigma(X(\omega)) P(X(\omega)) \dd \omega \\
&= \sum_{\sigma \in \mathfrak{S}_n} \int_{\omega \in \Omega} \varphi(X(\omega)) P(X(\omega)) 1_{X_1 \leq \cdots \leq X_n} \dd \omega \\
&= n! \int_{\omega \in \Omega} \varphi(X(\omega)) P(X(\omega)) 1_{X_1 \leq \cdots \leq X_n} \dd \omega \\
&= n!\, \mathbb{E}[\varphi(X(\omega)) 1_{X_1 \leq \cdots \leq X_n}]
\end{align*}

\item We write $(X_{(1)}, \cdots, X_{(n)}) = \sigma(X)$. Then notice that:
\[
f_{\sigma(X)}(\vb{x}) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} f_X(\mu^{-1}(\vb{x})) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} f_X(\mu(\vb{x})) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} \prod_{i = 1}^n f_{X_i}(\mu(\vb{x})_i) \dd \vb{x}
\]
Where one the last equality we used that the $X_i$ are independent. Then since the $X_i$ are identically distributed we have that $\forall i, \, f_{X_i} = f_{X_1}$. Now since the product commutes we have that the terms inside the sum are all equal up to a permutation of the terms, hence:
\[
\sum_{\mu \in \mathfrak{S}_n} \prod_{i = 1}^n f_{X_i}(\mu(\vb{x})_i) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} \left( \prod_{i = 1}^n f_{X_1}(x_i) \dd x_i \right) = n!\left( \prod_{i = 1}^n f_{X_1}(x_i) \dd x_i \right) = n! f_X(\vb{x'}) 1_{\vb{x'} = \mu(\vb{x})} \dd \vb{x'}
\]
Where we are free to chose any $\mu \in \mathfrak{S}_n$ since the terms in the product commute. If we fix ourselves with the choice $\mu = \sigma$ we get:
\[
\sum_{\mu \in \mathfrak{S}_n} \prod_{i = 1}^n f_{X_i}(\mu(\vb{x})_i) \dd \vb{x} = n! f_X(\sigma(\vb{x})) = n! f_X(\vb{x'}) 1_{\vb{x'} = \sigma(\vb{x})} \dd \vb{x}
\]
Then plugging this in the definition of the expectancy we get:
\begin{align*}
E[\varphi(\sigma(X))] &= \int_{\vb{x} \in \Omega} \varphi(\sigma(X(\vb{x}))) f_{\sigma(X)}(\vb{x}) \dd \vb{x} = n! \int_{\vb{x} \in \Omega} \varphi(\sigma(X(\vb{x}))) f_{X}(\vb{x'}) 1_{\vb{x'} = \sigma(\vb{x})} \dd \vb{x} = n! \int_{\vb{x} \in \sigma(\Omega)} \varphi(X(\vb{x})) f_{X}(\vb{x}) \dd \vb{x}\\
&= n! \mathbb{E}[\varphi(X) 1_{\sigma}] \mbox{~~where~~} 1_\sigma(\vb{x}) = \begin{cases}
1 \mbox{~~if~~} \vb{x} = \sigma(\vb{x})\\
0 \mbox{~~otherwise.}
\end{cases}
\end{align*}


\end{enumerate}


\end{document}