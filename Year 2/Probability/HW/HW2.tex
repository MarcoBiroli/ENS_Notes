\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{tikz}
\usepackage{stmaryrd}

\usepackage[left=1cm,right=1cm,top=2cm,bottom=2cm]{geometry}
\author{Marco Biroli}
\title{HW2 - Probability}

\begin{document}
\maketitle

\section{Change of variables}
\begin{enumerate}

\item From the change of variable theorem we know that:
\[
f_{U, V}(u, v) = f_{X, Y}(uv, v(1 - u)) |J|^{-1}
\]
Where:
\[
J = \begin{vmatrix}
\frac{y}{(x+y)^2} & -\frac{x}{(x+y)^2}\\
1 & 1
\end{vmatrix} = \frac{1}{x+y} =  v^{-1}
\]
Then replacing in the definition and using the fact that $X$ and $Y$ are independent and hence we can split the joint law we get that:
\begin{align*}
f_{U,V}(u, v) &= \frac{uv^{k-1}}{(k-1)!} e^{-uv} 1_{\mathbb{R}^+}(uv) \frac{v^{k-1}(1 - u)^{k-1}}{(k - 1)!} e^{-v(1- u)} 1_{\mathbb{R}^+} (v(1 - u)) v\\
&= \frac{e^{-v} \sqrt{v^2} \left((1-u) u
   v^2\right)^{k-1}}{((k-1)!)^2} 1_{\mathbb{R}^+} (u v) 1_{\mathbb{R}^+}(v-u v)
\end{align*}
Then integrating for $u$ on $\mathbb{R}$ gives:
\[
f(v) = ...
\]

\item ...

\end{enumerate}

\section{Order statistics}

\begin{enumerate}

\item Let $(\Omega_i, \mathcal{F}_i, P_i)$ be the probability space of $X_i$ then define the product probability space as $(\Omega, \mathcal{F}, P)$. Let $(\Omega, \mathcal{F}, P)$ also be the probability space of $T$. Then we define:
\begin{align*}
X_T : \Omega &\longrightarrow \mathbb{R}\\
\vb{x} &\longmapsto \vb{x}_{T(\vb{x})}
\end{align*}
Then let $B \in \mathcal{B}(\mathbb{R})$ then we have that:
\begin{align*}
\{\vb{x} \in \Omega : X_T(\vb{x}) \in B\} &\subset \bigotimes_{i \in \llbracket 1, n \rrbracket} \{x_i \in \Omega_i :  X_i(x_i) \in B\} \in \mathcal{F}
\end{align*}
Where the belonging to $\mathcal{F}$ follows from the definition of the product $\sigma$-algebra. 

\item I think that $(X_{(1)}, \cdots, X_{(n)})$ is ill-defined since there exists no clear order relation on functions which might not even come from the same space. I assume that what was meant was that:
\[
\forall \omega \in \Omega, \exists \sigma \in \mathfrak{S}_n, \sigma(X(\omega)) = \sigma\left(\left(X_1(\omega_1), \cdots, X_n(\omega_n)\right)\right) = (X_{\sigma(1)}(\omega_{\sigma(1)}), \cdots, X_{\sigma(n)}(\omega_{\sigma(n)})) \mbox{~~ is in increasing order.} 
\]
Since we have a finite list of real numbers we know from the constructions of the real numbers we can order it. Then we define the permutation $\sigma_\omega$ as the one which sets them in the right order and in case of parity the smaller index goes first. Then we have that $\sigma$ is a random variable defined as:
\begin{align*}
\sigma : \Omega &\longrightarrow \mathfrak{S}_n\\
\omega &\longmapsto \sigma_\omega
\end{align*}
We furthermore have that $\sigma$ is injective and therefore measurable. Hence $\sigma$ is a well-defined random variable. 

\item From the previous question we write $(X_{(1)}, \cdots, X_{(n)}) = \sigma(X)$. Then notice that:
\[
f_{\sigma(X)}(\vb{x}) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} f_X(\mu^{-1}(\vb{x})) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} f_X(\mu(\vb{x})) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} \prod_{i = 1}^n f_{X_i}(\mu(\vb{x})_i) \dd \vb{x}
\]
Where on the last equality we used that the $X_i$ are independent. Then since the $X_i$ are identically distributed we have that $\forall i, \, f_{X_i} = f_{X_1}$. Now since the product commutes we have that the terms inside the sum are all equal up to a permutation of the terms, hence:
\[
\sum_{\mu \in \mathfrak{S}_n} \prod_{i = 1}^n f_{X_i}(\mu(\vb{x})_i) \dd \vb{x} = \sum_{\mu \in \mathfrak{S}_n} \left( \prod_{i = 1}^n f_{X_1}(x_i) \dd x_i \right) = n!\left( \prod_{i = 1}^n f_{X_1}(x_i) \dd x_i \right) = n! f_X(\vb{x'}) 1_{\vb{x'} = \mu(\vb{x})} \dd \vb{x'}
\]
Where we are free to chose any $\mu \in \mathfrak{S}_n$ since the terms in the product commute. If we fix ourselves with the choice $\mu = \sigma$ we get:
\[
\sum_{\mu \in \mathfrak{S}_n} \prod_{i = 1}^n f_{X_i}(\mu(\vb{x})_i) \dd \vb{x} = n! f_X(\sigma(\vb{x})) = n! f_X(\vb{x'}) 1_{\vb{x'} = \sigma(\vb{x})} \dd \vb{x}
\]
Call $\mu$ the function that maps $X_1, \cdots, X_n$ to $X_1, \cdots, X_n - X_{n-1}$. Then plugging this in the definition of the expectancy we get:
\begin{align*}
E[\varphi(\mu(\sigma(X)))] &= \int_{\vb{x} \in \Omega} \varphi(\mu(\sigma(X(\vb{x})))) f_{\mu(\sigma(X))}(\mu(\vb{x})) \dd \vb{x} = n! \int_{\vb{x} \in \Omega} \varphi(\mu(\sigma(X(\vb{x})))) f_{X}(\vb{x'}) 1_{\vb{x'} = \sigma(\vb{x})} \dd \vb{x}\\
&= n! \int_{\vb{x} \in \sigma(\Omega)} \varphi(\mu(X(\vb{x}))) f_{X}(\vb{x}) \dd \vb{x} = n! \mathbb{E}[\mu(\varphi(X)) 1_{\sigma}] \mbox{~~where~~} 1_\sigma(\vb{x}) = \begin{cases}
1 \mbox{~~if~~} \vb{x} = \sigma(\vb{x})\\
0 \mbox{~~otherwise.}
\end{cases}
\end{align*}

\item From the Block grouping theorem we know that if $X_1, \cdots, X_n$ are independent then $X_1, X_2 - X_1, \cdots, X_{n} - X_{n-1}$ are independent. Hence taking $\varphi(\mu(\vb{x})) = \prod_{i = 1}^n g_i(\mu(\vb{x_i}))$ where all the $f_i$ are measurable we get that:
\[
\mathbb{E}\left[\prod_{i = 1}^n g_i(\mu(\sigma(X))_i)\right] = \mathbb{E}\left[ n!\, 1_\sigma \prod_{i = 1}^n g_i(\mu(X)_i)\right] = n! \prod_{i = 1}^n \int_{\vb{x} \in \Omega} f_{X_1}(g_i(\mu(X(\vb{x}))_i)) P(\vb{x} = \sigma(\vb{x})) \dd \vb{x} = \prod_{i = 1}^n \mathbb{E}[g_i(\mu(\sigma(X))_i] 
\] 
Hence the $\mu(\sigma(X))$ are independent. Notice that in the first equality we used question 3, in the second equality we used the independence of $\mu(X)$ and in the third we simply used that $P(\vb{x} = \sigma(\vb{x})) = \frac{1}{n!}$ and then recontract the integral into an expectancy.
Then we have that $X_{(1)} = \min_i X_i$ hence:
\[
F_{X_{(1)}}(x) = 1 - \prod_{i = 1}^n P(X_i > x) = 1 - \prod_{i = 1}^n e^{- \alpha x} = 1 - e^{- \alpha n x}
\]
So $X_{(1)}$ follows an exponential law of parameter $n \alpha$. Now consider $X_{(i+1)} - X_{(i)}$. We have that this can be re-written as:
\[
X_{(i+1)} - X_{(i)} = \min_{i \in \llbracket 1, n \rrbracket, X_i > X_{(i)}} X_i - X_{(i)}
\]
However notice that:
\[
P(X_i = x + y | X_i > x) = \frac{P(X_i = x+ y \cap X_i > x)}{P(X_i > x)} = \frac{\alpha e^{-\alpha(x+y)}}{e^{-\alpha x}} = \alpha e^{-\alpha y} = P(X_i = y)
\]
Hence we get that:
\[
X_{(i+1)} - X_{(i)} = \min_{i \in \llbracket 1, n - i\rrbracket} X_i \sim \mbox{Exp}(\alpha(n - i))
\]


\item It is well know that the expectancy of an exponential random variable of parameter $\alpha$ is given by $\frac{1}{\alpha}$. Hence from the previous question we have that:
\[
\mathbb{E}[X_{(i+1)} - X_{(i)}] = \frac{1}{\alpha(n - i)} \mbox{~~and~~} \mathbb{E}[X_{(1)}] = \frac{1}{\alpha n }
\]
Denote by $u_i = \mathbb{E}[X_{(i)}]$ then we have that:
\[
u_1 = \frac{1}{\alpha n} \mbox{~~and~~} u_{i+1} = u_i + \frac{1}{\alpha(n - i)} = \sum_{\ell = 0}^{i} \frac{1}{\alpha(n - \ell)}
\]
Now the sum can be written as:
\[
\sum_{\ell = 0}^i \frac{1}{\alpha(n - \ell)} = \frac{1}{\alpha}\left( \sum_{\ell = 0}^{n-1} \frac{1}{n - \ell} - \sum_{\ell = i + 1}^{n-1} \frac{1}{n - \ell} \right) = \frac{1}{\alpha} \left( \sum_{\ell = 1}^n \frac{1}{\ell} - \sum_{\ell = 1}^{n - i - 1} \frac{1}{\ell} \right) = \frac{1}{\alpha} \left( \sum_{\ell = 1}^n \frac{1}{\ell} - \gamma - (\sum_{\ell = 1}^{n - i - 1} \frac{1}{\ell} - \gamma) \right) 
\]
Now using the definition of the digamma function we have that:
\[
\sum_{\ell = 0}^i = \frac{1}{\alpha}\left( \frac{\Gamma'(n+1)}{\Gamma(n+1)} + \frac{\Gamma'(n-i)}{\Gamma(n-i)} \right)
\]

\item Notice that:
\[
f_{X_{(k)}} = f_{X_{(1)} + (X_{(2)} - X_{(1)}) + \cdots + (X_{(k)} - X_{(k-1)}} = f_{X_{(1)}} \star f_{X_{(2)} - X_{(1)}} \star \cdots \star f_{X_{(k)} - X_{(k-1)}}
\]
Or in other words if we denote by $Y_j$ exponential random variables of parameter $\alpha$ we have that:
\[
X_{(k)} = \sum_{i = 1}^{k-1} X_{(i)} - X_{(i-1)} 1_{i > 1} = \sum_{i = 1}^k \frac{Y_i}{n - i + 1}
\]

\item In general we have that:
\[
F_{X_{(k)}}(x) = P\left(\max_{i \in \mathcal{I}} X_i < x \land \min_{i \in \llbracket 1, n \rrbracket \setminus \mathcal{I}} X_i > x \big| |\mathcal{I}| = k\right) = \binom{n}{k} F_{X_1}(x)^k (1 - F_{X_1}(x))^{n - k}
\]


\end{enumerate}


\end{document}